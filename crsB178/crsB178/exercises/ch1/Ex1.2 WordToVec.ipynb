{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex1.2 WordToVec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that all the other kernels are shut down otherwise you might run out of resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will experiment with word embeddings of all the State of the Union speeches. Ideally words that are close in meaning should get vectors that are close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2192,
     "status": "ok",
     "timestamp": 1593441681356,
     "user": {
      "displayName": "Chris Mawata",
      "photoUrl": "",
      "userId": "00563691954886767594"
     },
     "user_tz": 240
    },
    "id": "LSvuoAAenxLj"
   },
   "outputs": [],
   "source": [
    "# Imports needed packages.\n",
    "import gzip\n",
    "import gensim \n",
    "import logging\n",
    "\n",
    "# Configures the logging.\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to supress warnings about planned deprecation of some methods.\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function that will load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rT_VSPLvwvV-"
   },
   "outputs": [],
   "source": [
    "def read_input(input_file):\n",
    "    logging.info(\"reading file {0}...this may take a while\".format(input_file))\n",
    "    count = 0\n",
    "    with open(input_file, 'r') as f:\n",
    "      while True:\n",
    "        count += 1\n",
    "        line = f.readline()\n",
    "        if not line:\n",
    "          break\n",
    "#       Do some pre-processing using the gensim library.\n",
    "#       The simple_preprocess() method returns a list of words for each speech. Each \"line\" is a speech.\n",
    "        yield gensim.utils.simple_preprocess(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the speeches have previously been put in a single file, sotu.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 118417,
     "status": "ok",
     "timestamp": 1593441842933,
     "user": {
      "displayName": "Chris Mawata",
      "photoUrl": "",
      "userId": "00563691954886767594"
     },
     "user_tz": 240
    },
    "id": "zOGvxFCPsxTU",
    "outputId": "54e73adf-424c-449e-e783-58f0350f5abb"
   },
   "outputs": [],
   "source": [
    "data_file = 'sotu.txt'\n",
    "with open(data_file) as file:\n",
    "    raw_speeches = [line.rstrip() for line in file]\n",
    "documents = list (read_input (data_file))\n",
    "logging.info (\"Done reading data file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each entry in the documents list is itself a list of words that came from a speech. \n",
    "# Here, for instance, is the speech at index 0. \n",
    "documents[0]\n",
    "# The list is a bit long and might clutter your screen so if you want it to go away after you have looked at it, then \n",
    "# right click on the output and select \"Clear Outputs\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents[0] is itself a list so we have a list of lists.\n",
    "type(documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build the vocabluary and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 38006,
     "status": "ok",
     "timestamp": 1593442029010,
     "user": {
      "displayName": "Chris Mawata",
      "photoUrl": "",
      "userId": "00563691954886767594"
     },
     "user_tz": 240
    },
    "id": "21V0OZtptKQp",
    "outputId": "ac99f9c0-b657-47ff-bcb7-873fedc34dfd"
   },
   "outputs": [],
   "source": [
    "# You can reduce verbosity if you like by raising the log level, say to ERROR.\n",
    "# You can right click on the result and select \"Clear Outputs\" if it gets too cluttered.\n",
    "logging.root.level = logging.INFO\n",
    "\n",
    "model = gensim.models.Word2Vec(\n",
    "        documents,\n",
    "        vector_size = 150, # Number of dimensions in the vector space.\n",
    "        window = 10, # Maximum distance between the current and predicted word within a sentence.\n",
    "        min_count = 2,\n",
    "        workers = 10, # Number of threads to use.\n",
    "        epochs = 20) #Number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 631,
     "status": "ok",
     "timestamp": 1593442318194,
     "user": {
      "displayName": "Chris Mawata",
      "photoUrl": "",
      "userId": "00563691954886767594"
     },
     "user_tz": 240
    },
    "id": "Ib8kmGL8z6df",
    "outputId": "ae1a7e67-b341-4dc1-b856-f1f975c3881f"
   },
   "outputs": [],
   "source": [
    "# Now that we have a model, lets search for some word associations.\n",
    "word = \"sea\"\n",
    "model.wv.most_similar(word, topn = 10)\n",
    "# Try a few other words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Hm8zMaorfyK"
   },
   "source": [
    "## Document to Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y_dByLAXrgg8"
   },
   "source": [
    "DocToVec is the same idea as WordToVec but now it is the distance between similar documents, ones with many words in common, that should be small. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 711,
     "status": "ok",
     "timestamp": 1593444651841,
     "user": {
      "displayName": "Chris Mawata",
      "photoUrl": "",
      "userId": "00563691954886767594"
     },
     "user_tz": 240
    },
    "id": "2Am3FM7Or04r"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1176,
     "status": "ok",
     "timestamp": 1593444654021,
     "user": {
      "displayName": "Chris Mawata",
      "photoUrl": "",
      "userId": "00563691954886767594"
     },
     "user_tz": 240
    },
    "id": "bp87QbMpsreU"
   },
   "outputs": [],
   "source": [
    "# A TaggedDocument is just the list of words in a document plus an associated tag. \n",
    "# We will just use an integer as a label. We create a list of TaggedDocument objects, \n",
    "# one for each of our speeches.\n",
    "tagged_documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(documents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the TaggedDocument at index 0.\n",
    "tagged_documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13420,
     "status": "ok",
     "timestamp": 1593444718429,
     "user": {
      "displayName": "Chris Mawata",
      "photoUrl": "",
      "userId": "00563691954886767594"
     },
     "user_tz": 240
    },
    "id": "w9NmREEw7DeE",
    "outputId": "24594e19-71b5-450d-f96d-6c26ecb33dc4"
   },
   "outputs": [],
   "source": [
    "# We create the vectors, one for each document in tagged_documents.\n",
    "d2v_model = Doc2Vec(\n",
    "    tagged_documents, \n",
    "    vector_size = 100, \n",
    "    window = 10, \n",
    "    min_count = 500, # Ignore words with total frequency less than this.\n",
    "    workers = 2, \n",
    "    epochs = 10,\n",
    "    dm = 1, # Use distributed memory algorithm rather than bag of words.\n",
    "    alpha = 0.025, # Learning rate at the beginning.\n",
    "    min_alpha = 0.001 # Learning rate tapers down to this.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We train the model, i.e. calculate the distances between the vectors representing the documents.\n",
    "logging.root.level = logging.ERROR\n",
    "d2v_model.train(\n",
    "    tagged_documents, \n",
    "    total_examples = d2v_model.corpus_count, \n",
    "    epochs = 10, \n",
    "    start_alpha = 0.002, \n",
    "    end_alpha = -0.016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which documents are most similar to document 57?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 686,
     "status": "ok",
     "timestamp": 1593445564262,
     "user": {
      "displayName": "Chris Mawata",
      "photoUrl": "",
      "userId": "00563691954886767594"
     },
     "user_tz": 240
    },
    "id": "1wdTkkNnvE7k",
    "outputId": "5bdeb4a7-474a-4d15-e050-20b9e715b692"
   },
   "outputs": [],
   "source": [
    "d2v_model.docvecs.most_similar(57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are curious you can take a look at the originals and compare them. \n",
    "# They are rather long but here is speech 57:\n",
    "raw_speeches[57]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering is a machine learning algorithm where similar items are in the same \"cluster\" while disimilar items are in different clusters. We can cluster the speeches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 521,
     "status": "ok",
     "timestamp": 1593445046939,
     "user": {
      "displayName": "Chris Mawata",
      "photoUrl": "",
      "userId": "00563691954886767594"
     },
     "user_tz": 240
    },
    "id": "tXmg2APauVZQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_model.docvecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We create a KMeans model instance\n",
    "kmeans_model = KMeans(\n",
    "    n_clusters = 4, \n",
    "    init = 'k-means++', \n",
    "    max_iter = 100) \n",
    "# The docs-to-vec object we created has a vector for each document\n",
    "# Since the distance between the vectors represent similarity \n",
    "# we cluster the vectors\n",
    "X = kmeans_model.fit(d2v_model.docvecs.vectors)\n",
    "# Each vector now has a label, the cluster to which it belongs\n",
    "labels = kmeans_model.labels_.tolist()\n",
    "#l = kmeans_model.fit_predict(d2v_model.docvecs.vectors)\n",
    "l=0\n",
    "# In order to draw 2D pictures we use PCA to create a 2D projection\n",
    "# that loses as little information as possible\n",
    "pca = PCA(n_components=2).fit(d2v_model.docvecs.vectors)\n",
    "datapoint = pca.transform(d2v_model.docvecs.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1316,
     "status": "ok",
     "timestamp": 1593445050117,
     "user": {
      "displayName": "Chris Mawata",
      "photoUrl": "",
      "userId": "00563691954886767594"
     },
     "user_tz": 240
    },
    "id": "uL08ZO1ctkIr",
    "outputId": "0973fed9-610e-4c0e-e6ce-b0908a7e8fe2"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# In order to draw 2D pictures we use PCA to create a 2D projection\n",
    "# that loses as little information as possible\n",
    "pca = PCA(n_components=2).fit(d2v_model.docvecs.vectors)\n",
    "datapoint = pca.transform(d2v_model.docvecs.vectors)\n",
    "\n",
    "plt.figure\n",
    "# These will be the colors given to the clusters\n",
    "label_col = ['#FFFF00', '#008000', '#0000FF', '#800080']\n",
    "color = [label_col[i] for i in labels]\n",
    "plt.scatter(datapoint[:, 0], datapoint[:, 1], c=color)\n",
    "\n",
    "# We draw the centroids\n",
    "centroids = kmeans_model.cluster_centers_\n",
    "centroidpoint = pca.transform(centroids)\n",
    "plt.scatter(centroidpoint[:, 0], centroidpoint[:, 1], marker = '^', s = 150, c = '#000000')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than a graphic, we might want a listing of the cluster memberships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_fuIt9Kfryqy"
   },
   "outputs": [],
   "source": [
    "print (kmeans_model.labels_)\n",
    "print('\\n')\n",
    "\n",
    "#create a dictionary to get cluster data\n",
    "clusters={0:[],1:[],2:[],3:[]}\n",
    "for i in range(len(tagged_documents)):\n",
    "    clusters[kmeans_model.labels_[i]].append(i)\n",
    "for i in range(len(clusters)):\n",
    "    print(\"Cluster\",i,clusters[i],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the cluster in which speech 57 lies:\n",
    "clusters[kmeans_model.labels_[57]]\n",
    "# Are the speeches that the most_similar() method said were closest to speech 57 in the same cluster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.perf_counter()\n",
    "print(\"Time taken: in min\", (end - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP3moieMFJ6JrTuW6fbjM4s",
   "name": "wordToVec.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
